{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pysr import PySRRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "#from causallearn.search.ConstraintBased.PC import pc\n",
    "\n",
    "#import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_scatter_para=['ETG','T-type','Bar', 'Disk', 'Ring', 'Core', 'Multiple', 'Compactness', 'AGN',\n",
    "       'Pseudobulge', 'BCG', 'cD','M*_sph', 'M*_gal', 'log_B/T',\n",
    "       'log_sigma0', 'log_R_e_sph_maj','log_R_e_sph_eq_kpc', 'log_n_sph_maj', 'log_n_sph_eq', 'log(I_e,sph,maj/M_Sun/pc^2)',\n",
    "       'log(I_e,sph,eq/M_Sun/pc^2)', 'Concentration_Index',\n",
    "       'avg_Rho_1kpc_Exact_All', 'r1_density_approx', 'log10(R10_kpc)',\n",
    "       'logRho_R10_approx', 'log_rho10_Exact', 'log10(R90_kpc)',\n",
    "       'logRho_R90_approx', 'log_rho_90_Exact_all', 'Rho_re_spatial',\n",
    "       'SR_pc_All', 'Rho_SR_pc_All', 'CR_def1_approx_new',\n",
    "       'Rho_cr_def1_approx_new', 'CR_def2_approx_new',\n",
    "       'Rho_CR_def2_approx_new', 'Sr(pc)_2_using_Falserm_drho',\n",
    "       'Log_Approx_Avg_density_10pc', 'log_Rho_e_Exact_new',\n",
    "       'logRho_e_approx_New', 'logRho_soi_approx_new',\n",
    "       'log_Rho_soi_exact_new', 'Avg_Rho_Re_Exact_all',\n",
    "       'Avg_Rho_soi_exact_all', 'Avg_Rho_re_Exact_all', 'Rho_re_Exact_all',\n",
    "       'Rho_r_soi_2BH_approx', 'Log_Avg_Rho_10kpc_approx',\n",
    "       'Log_Avg_Rho_10kpc_exact_final', 'Log_Avg_Rho_100pc_approx',\n",
    "       'Log_Avg_Rho_5kpc_approx', 'Log_Avg_rho_5kpc_exact_all', 'ube', 'bve',\n",
    "       'dc', 'bvtc', 'bri25', 'mabs', 'blum', 'logblum', 'logSigma0sph',\n",
    "       'LogSigma0', 'R10', 'logR10', 'logR10phi', 'Rh', 'logRh', 'logRhphi',\n",
    "       'logHalo','M_BH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "df_full = pd.read_csv('../SMBH_Data_0911.csv',header=1)\n",
    "\n",
    "\n",
    "paras=low_scatter_para.copy()\n",
    "if paras[-1]!='M_BH':\n",
    "    paras.append('M_BH')\n",
    "paras.append('M_BH_std')\n",
    "\n",
    "obs=df_full.copy()\n",
    "obs = obs[paras].dropna(axis='index',how='any')\n",
    "print(len(obs))\n",
    "\n",
    "y = obs['M_BH'].to_numpy()\n",
    "w = 1/obs['M_BH_std'].to_numpy()**2\n",
    "\n",
    "X = obs.iloc[:,:-2].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start over 100 times, each time evolve 300 generations\n",
    "evolutions = 3\n",
    "niterations = 3\n",
    "#evolutions = 100\n",
    "#niterations = 300\n",
    "\n",
    "\n",
    "denoise=False\n",
    "ncyclesperiteration=5000\n",
    "adaptive_parsimony_scaling=20\n",
    "verbosity=0\n",
    "return_model=True\n",
    "maxsize=20\n",
    "optimizer_algorithm=\"NelderMead\"\n",
    "optimizer_iterations=100\n",
    "should_simplify=True\n",
    "temp_equation_file=True  # turn this on will prevent the auto-save of hall_of_fame\n",
    "tempdir='/data/zj448/SR/Ultimate_paper/temp/'  # dummy dir to save temp files and then being auto deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zj448/miniconda3/lib/python3.9/site-packages/pysr/sr.py:1346: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n",
      "/home/zj448/miniconda3/lib/python3.9/site-packages/pysr/sr.py:1937: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, or, alternatively, do a dimensionality reduction beforehand. For example, `X = PCA(n_components=6).fit_transform(X)`, using scikit-learn's `PCA` class, will reduce the number of features to 6 in an interpretable way, as each resultant feature will be a linear combination of the original features. \n",
      "  warnings.warn(\n",
      "/home/zj448/miniconda3/lib/python3.9/site-packages/pysr/sr.py:1346: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n",
      "/home/zj448/miniconda3/lib/python3.9/site-packages/pysr/sr.py:1937: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, or, alternatively, do a dimensionality reduction beforehand. For example, `X = PCA(n_components=6).fit_transform(X)`, using scikit-learn's `PCA` class, will reduce the number of features to 6 in an interpretable way, as each resultant feature will be a linear combination of the original features. \n",
      "  warnings.warn(\n",
      "/home/zj448/miniconda3/lib/python3.9/site-packages/pysr/sr.py:1346: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n",
      "/home/zj448/miniconda3/lib/python3.9/site-packages/pysr/sr.py:1937: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, or, alternatively, do a dimensionality reduction beforehand. For example, `X = PCA(n_components=6).fit_transform(X)`, using scikit-learn's `PCA` class, will reduce the number of features to 6 in an interpretable way, as each resultant feature will be a linear combination of the original features. \n",
      "  warnings.warn(\n",
      "/home/zj448/miniconda3/lib/python3.9/site-packages/pysr/sr.py:1346: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n",
      "/home/zj448/miniconda3/lib/python3.9/site-packages/pysr/sr.py:1937: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, or, alternatively, do a dimensionality reduction beforehand. For example, `X = PCA(n_components=6).fit_transform(X)`, using scikit-learn's `PCA` class, will reduce the number of features to 6 in an interpretable way, as each resultant feature will be a linear combination of the original features. \n",
      "  warnings.warn(\n",
      "/home/zj448/miniconda3/lib/python3.9/site-packages/pysr/sr.py:1346: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n",
      "/home/zj448/miniconda3/lib/python3.9/site-packages/pysr/sr.py:1937: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, or, alternatively, do a dimensionality reduction beforehand. For example, `X = PCA(n_components=6).fit_transform(X)`, using scikit-learn's `PCA` class, will reduce the number of features to 6 in an interpretable way, as each resultant feature will be a linear combination of the original features. \n",
      "  warnings.warn(\n",
      "/home/zj448/miniconda3/lib/python3.9/site-packages/pysr/sr.py:1346: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n",
      "/home/zj448/miniconda3/lib/python3.9/site-packages/pysr/sr.py:1937: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, or, alternatively, do a dimensionality reduction beforehand. For example, `X = PCA(n_components=6).fit_transform(X)`, using scikit-learn's `PCA` class, will reduce the number of features to 6 in an interpretable way, as each resultant feature will be a linear combination of the original features. \n",
      "  warnings.warn(\n",
      "/home/zj448/miniconda3/lib/python3.9/site-packages/pysr/sr.py:1346: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n",
      "/home/zj448/miniconda3/lib/python3.9/site-packages/pysr/sr.py:1937: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, or, alternatively, do a dimensionality reduction beforehand. For example, `X = PCA(n_components=6).fit_transform(X)`, using scikit-learn's `PCA` class, will reduce the number of features to 6 in an interpretable way, as each resultant feature will be a linear combination of the original features. \n",
      "  warnings.warn(\n",
      "/home/zj448/miniconda3/lib/python3.9/site-packages/pysr/sr.py:1346: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n",
      "/home/zj448/miniconda3/lib/python3.9/site-packages/pysr/sr.py:1937: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, or, alternatively, do a dimensionality reduction beforehand. For example, `X = PCA(n_components=6).fit_transform(X)`, using scikit-learn's `PCA` class, will reduce the number of features to 6 in an interpretable way, as each resultant feature will be a linear combination of the original features. \n",
      "  warnings.warn(\n",
      "/home/zj448/miniconda3/lib/python3.9/site-packages/pysr/sr.py:1346: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n",
      "/home/zj448/miniconda3/lib/python3.9/site-packages/pysr/sr.py:1937: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, or, alternatively, do a dimensionality reduction beforehand. For example, `X = PCA(n_components=6).fit_transform(X)`, using scikit-learn's `PCA` class, will reduce the number of features to 6 in an interpretable way, as each resultant feature will be a linear combination of the original features. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(evolutions):\n",
    "\n",
    "    warm_start=False\n",
    "\n",
    "    for iter in range(niterations):\n",
    "        model = PySRRegressor(\n",
    "            binary_operators=[\"+\", \"-\", \"*\", \"/\",\"pow\"],\n",
    "            unary_operators=[\"exp\",\"log10\"],\n",
    "            constraints={\"pow\": (9, 1)}, # power laws can have 9 complexity left argument, but only 1 complexity in the right argument.\n",
    "            warm_start=warm_start,\n",
    "            denoise=denoise,\n",
    "            niterations=1,\n",
    "            ncyclesperiteration=ncyclesperiteration,\n",
    "            adaptive_parsimony_scaling=adaptive_parsimony_scaling,\n",
    "            verbosity=verbosity,\n",
    "            precision=64,\n",
    "            maxsize=maxsize,\n",
    "            optimizer_algorithm=optimizer_algorithm,\n",
    "            optimizer_iterations=optimizer_iterations,\n",
    "            should_simplify=should_simplify,\n",
    "            temp_equation_file=temp_equation_file,\n",
    "            tempdir=tempdir,\n",
    "            )\n",
    "        \n",
    "\n",
    "        model.fit(X=X, y=y, weights=w)\n",
    "\n",
    "\n",
    "        equations = model.equations_\n",
    "    \n",
    "        number_matching_pattern = r\"(?<![a-zA-Z0-9_.])[+-]?(\\d+\\.\\d+|\\.\\d+|\\d+\\.|\\d+)(?:[eE][-+]?\\d+)?\"\n",
    "\n",
    "        variable_matching_pattern = r'\\bx\\d+'\n",
    "\n",
    "\n",
    "        # Count number of constants:\n",
    "        equations[\"number_constants\"] = [len(re.findall(number_matching_pattern, eq)) for eq in equations[\"equation\"]]\n",
    "\n",
    "        # count number of (unique) variables\n",
    "        equations[\"number_variables\"] = [len(re.findall(variable_matching_pattern, eq)) for eq in equations[\"equation\"]]\n",
    "        equations[\"unique_number_variables\"] = [len(set(re.findall(variable_matching_pattern, eq))) for eq in equations[\"equation\"]]\n",
    "\n",
    "        # Compute log likelihood (for example)\n",
    "        equations[\"log_like\"] = - equations[\"loss\"] * len(X)\n",
    "\n",
    "        # Compute AIC:\n",
    "        equations[\"aic\"] = 2 * equations[\"number_constants\"] - 2 * equations[\"log_like\"]\n",
    "\n",
    "        equations.to_csv('/data/zj448/SR/Ultimate_paper/pareto_archive/pareto_'+str(epoch)+'_'+str(iter)+'.csv')\n",
    "\n",
    "        warm_start=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complexity</th>\n",
       "      <th>loss</th>\n",
       "      <th>score</th>\n",
       "      <th>equation</th>\n",
       "      <th>sympy_format</th>\n",
       "      <th>lambda_format</th>\n",
       "      <th>number_constants</th>\n",
       "      <th>number_variables</th>\n",
       "      <th>unique_number_variables</th>\n",
       "      <th>log_like</th>\n",
       "      <th>aic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.284935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>x69</td>\n",
       "      <td>x69</td>\n",
       "      <td>PySRFunction(X=&gt;x69)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-528.493489</td>\n",
       "      <td>1056.986978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.312159</td>\n",
       "      <td>1.414552</td>\n",
       "      <td>(x13 + -2.7246199129259274)</td>\n",
       "      <td>x13 - 2.7246199129259274</td>\n",
       "      <td>PySRFunction(X=&gt;x13 - 2.7246199129259274)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-31.215879</td>\n",
       "      <td>64.431757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.280564</td>\n",
       "      <td>0.106711</td>\n",
       "      <td>(x69 - exp(x3))</td>\n",
       "      <td>x69 - exp(x3)</td>\n",
       "      <td>PySRFunction(X=&gt;x69 - exp(x3))</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-28.056389</td>\n",
       "      <td>56.112778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.189309</td>\n",
       "      <td>0.393419</td>\n",
       "      <td>(x13 + (x16 - 3.1255318803272307))</td>\n",
       "      <td>x13 + x16 - 3.1255318803272307</td>\n",
       "      <td>PySRFunction(X=&gt;x13 + x16 - 3.1255318803272307)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-18.930941</td>\n",
       "      <td>39.861882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.143736</td>\n",
       "      <td>0.275406</td>\n",
       "      <td>(exp(exp(exp(x53))) - -4.332799083256326)</td>\n",
       "      <td>exp(exp(exp(x53))) + 4.332799083256326</td>\n",
       "      <td>PySRFunction(X=&gt;exp(exp(exp(x53))) + 4.3327990...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-14.373573</td>\n",
       "      <td>30.747146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.142545</td>\n",
       "      <td>0.004160</td>\n",
       "      <td>((x69 - exp(1.0451524346431438 ^ x30)) + x17)</td>\n",
       "      <td>x17 + x69 - exp(1.0451524346431438**x30)</td>\n",
       "      <td>PySRFunction(X=&gt;x17 + x69 - exp(1.045152434643...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-14.254474</td>\n",
       "      <td>30.508948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0.140679</td>\n",
       "      <td>0.013176</td>\n",
       "      <td>((((x69 + x16) / 1.2782770440195763) - 0.44736...</td>\n",
       "      <td>0.78230302631069185*x16 + x5 + 0.7823030263106...</td>\n",
       "      <td>PySRFunction(X=&gt;0.78230302631069185*x16 + x5 +...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-14.067884</td>\n",
       "      <td>32.135768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>0.129010</td>\n",
       "      <td>0.043297</td>\n",
       "      <td>((((x69 + x16) / 1.2782770440195763) - 0.44736...</td>\n",
       "      <td>0.78230302631069185*x16 + 0.80306845625943204*...</td>\n",
       "      <td>PySRFunction(X=&gt;0.78230302631069185*x16 + 0.80...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-12.900953</td>\n",
       "      <td>31.801906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>0.058537</td>\n",
       "      <td>0.395110</td>\n",
       "      <td>(x13 + (-0.4083174827029943 - log10(exp(((x42 ...</td>\n",
       "      <td>x13 - log(exp(x5 + 6.715533487955264*x42/x39))...</td>\n",
       "      <td>PySRFunction(X=&gt;x13 - log(exp(x5 + 6.715533487...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.853746</td>\n",
       "      <td>15.707491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   complexity      loss     score  \\\n",
       "0           1  5.284935  0.000000   \n",
       "1           3  0.312159  1.414552   \n",
       "2           4  0.280564  0.106711   \n",
       "3           5  0.189309  0.393419   \n",
       "4           6  0.143736  0.275406   \n",
       "5           8  0.142545  0.004160   \n",
       "6           9  0.140679  0.013176   \n",
       "7          11  0.129010  0.043297   \n",
       "8          13  0.058537  0.395110   \n",
       "\n",
       "                                            equation  \\\n",
       "0                                                x69   \n",
       "1                        (x13 + -2.7246199129259274)   \n",
       "2                                    (x69 - exp(x3))   \n",
       "3                 (x13 + (x16 - 3.1255318803272307))   \n",
       "4          (exp(exp(exp(x53))) - -4.332799083256326)   \n",
       "5      ((x69 - exp(1.0451524346431438 ^ x30)) + x17)   \n",
       "6  ((((x69 + x16) / 1.2782770440195763) - 0.44736...   \n",
       "7  ((((x69 + x16) / 1.2782770440195763) - 0.44736...   \n",
       "8  (x13 + (-0.4083174827029943 - log10(exp(((x42 ...   \n",
       "\n",
       "                                        sympy_format  \\\n",
       "0                                                x69   \n",
       "1                           x13 - 2.7246199129259274   \n",
       "2                                      x69 - exp(x3)   \n",
       "3                     x13 + x16 - 3.1255318803272307   \n",
       "4             exp(exp(exp(x53))) + 4.332799083256326   \n",
       "5           x17 + x69 - exp(1.0451524346431438**x30)   \n",
       "6  0.78230302631069185*x16 + x5 + 0.7823030263106...   \n",
       "7  0.78230302631069185*x16 + 0.80306845625943204*...   \n",
       "8  x13 - log(exp(x5 + 6.715533487955264*x42/x39))...   \n",
       "\n",
       "                                       lambda_format  number_constants  \\\n",
       "0                               PySRFunction(X=>x69)                 0   \n",
       "1          PySRFunction(X=>x13 - 2.7246199129259274)                 1   \n",
       "2                     PySRFunction(X=>x69 - exp(x3))                 0   \n",
       "3    PySRFunction(X=>x13 + x16 - 3.1255318803272307)                 1   \n",
       "4  PySRFunction(X=>exp(exp(exp(x53))) + 4.3327990...                 1   \n",
       "5  PySRFunction(X=>x17 + x69 - exp(1.045152434643...                 1   \n",
       "6  PySRFunction(X=>0.78230302631069185*x16 + x5 +...                 2   \n",
       "7  PySRFunction(X=>0.78230302631069185*x16 + 0.80...                 3   \n",
       "8  PySRFunction(X=>x13 - log(exp(x5 + 6.715533487...                 2   \n",
       "\n",
       "   number_variables  unique_number_variables    log_like          aic  \n",
       "0                 1                        1 -528.493489  1056.986978  \n",
       "1                 1                        1  -31.215879    64.431757  \n",
       "2                 2                        2  -28.056389    56.112778  \n",
       "3                 2                        2  -18.930941    39.861882  \n",
       "4                 1                        1  -14.373573    30.747146  \n",
       "5                 3                        3  -14.254474    30.508948  \n",
       "6                 3                        3  -14.067884    32.135768  \n",
       "7                 3                        3  -12.900953    31.801906  \n",
       "8                 4                        4   -5.853746    15.707491  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complexity</th>\n",
       "      <th>loss</th>\n",
       "      <th>score</th>\n",
       "      <th>equation</th>\n",
       "      <th>sympy_format</th>\n",
       "      <th>lambda_format</th>\n",
       "      <th>number_constants</th>\n",
       "      <th>number_variables</th>\n",
       "      <th>unique_number_variables</th>\n",
       "      <th>log_like</th>\n",
       "      <th>aic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.284935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>x69</td>\n",
       "      <td>x69</td>\n",
       "      <td>PySRFunction(X=&gt;x69)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-528.493489</td>\n",
       "      <td>1056.986978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.312159</td>\n",
       "      <td>1.414552</td>\n",
       "      <td>(x13 + -2.7246199129259274)</td>\n",
       "      <td>x13 - 2.7246199129259274</td>\n",
       "      <td>PySRFunction(X=&gt;x13 - 2.7246199129259274)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-31.215879</td>\n",
       "      <td>64.431757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.280564</td>\n",
       "      <td>0.106711</td>\n",
       "      <td>(x69 - exp(x3))</td>\n",
       "      <td>x69 - exp(x3)</td>\n",
       "      <td>PySRFunction(X=&gt;x69 - exp(x3))</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-28.056389</td>\n",
       "      <td>56.112778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.189309</td>\n",
       "      <td>0.393419</td>\n",
       "      <td>(x13 + (x16 - 3.1255318803272307))</td>\n",
       "      <td>x13 + x16 - 3.1255318803272307</td>\n",
       "      <td>PySRFunction(X=&gt;x13 + x16 - 3.1255318803272307)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-18.930941</td>\n",
       "      <td>39.861882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.143736</td>\n",
       "      <td>0.275406</td>\n",
       "      <td>(exp(exp(exp(x53))) - -4.332799083256326)</td>\n",
       "      <td>exp(exp(exp(x53))) + 4.332799083256326</td>\n",
       "      <td>PySRFunction(X=&gt;exp(exp(exp(x53))) + 4.3327990...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-14.373573</td>\n",
       "      <td>30.747146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.142545</td>\n",
       "      <td>0.004160</td>\n",
       "      <td>((x69 - exp(1.0451524346431438 ^ x30)) + x17)</td>\n",
       "      <td>x17 + x69 - exp(1.0451524346431438**x30)</td>\n",
       "      <td>PySRFunction(X=&gt;x17 + x69 - exp(1.045152434643...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-14.254474</td>\n",
       "      <td>30.508948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0.140679</td>\n",
       "      <td>0.013176</td>\n",
       "      <td>((((x69 + x16) / 1.2782770440195763) - 0.44736...</td>\n",
       "      <td>0.78230302631069185*x16 + x5 + 0.7823030263106...</td>\n",
       "      <td>PySRFunction(X=&gt;0.78230302631069185*x16 + x5 +...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-14.067884</td>\n",
       "      <td>32.135768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>0.129010</td>\n",
       "      <td>0.043297</td>\n",
       "      <td>((((x69 + x16) / 1.2782770440195763) - 0.44736...</td>\n",
       "      <td>0.78230302631069185*x16 + 0.80306845625943204*...</td>\n",
       "      <td>PySRFunction(X=&gt;0.78230302631069185*x16 + 0.80...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-12.900953</td>\n",
       "      <td>31.801906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>0.058537</td>\n",
       "      <td>0.395110</td>\n",
       "      <td>(x13 + (-0.4083174827029943 - log10(exp(((x42 ...</td>\n",
       "      <td>x13 - log(exp(x5 + 6.715533487955264*x42/x39))...</td>\n",
       "      <td>PySRFunction(X=&gt;x13 - log(exp(x5 + 6.715533487...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.853746</td>\n",
       "      <td>15.707491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   complexity      loss     score  \\\n",
       "0           1  5.284935  0.000000   \n",
       "1           3  0.312159  1.414552   \n",
       "2           4  0.280564  0.106711   \n",
       "3           5  0.189309  0.393419   \n",
       "4           6  0.143736  0.275406   \n",
       "5           8  0.142545  0.004160   \n",
       "6           9  0.140679  0.013176   \n",
       "7          11  0.129010  0.043297   \n",
       "8          13  0.058537  0.395110   \n",
       "\n",
       "                                            equation  \\\n",
       "0                                                x69   \n",
       "1                        (x13 + -2.7246199129259274)   \n",
       "2                                    (x69 - exp(x3))   \n",
       "3                 (x13 + (x16 - 3.1255318803272307))   \n",
       "4          (exp(exp(exp(x53))) - -4.332799083256326)   \n",
       "5      ((x69 - exp(1.0451524346431438 ^ x30)) + x17)   \n",
       "6  ((((x69 + x16) / 1.2782770440195763) - 0.44736...   \n",
       "7  ((((x69 + x16) / 1.2782770440195763) - 0.44736...   \n",
       "8  (x13 + (-0.4083174827029943 - log10(exp(((x42 ...   \n",
       "\n",
       "                                        sympy_format  \\\n",
       "0                                                x69   \n",
       "1                           x13 - 2.7246199129259274   \n",
       "2                                      x69 - exp(x3)   \n",
       "3                     x13 + x16 - 3.1255318803272307   \n",
       "4             exp(exp(exp(x53))) + 4.332799083256326   \n",
       "5           x17 + x69 - exp(1.0451524346431438**x30)   \n",
       "6  0.78230302631069185*x16 + x5 + 0.7823030263106...   \n",
       "7  0.78230302631069185*x16 + 0.80306845625943204*...   \n",
       "8  x13 - log(exp(x5 + 6.715533487955264*x42/x39))...   \n",
       "\n",
       "                                       lambda_format  number_constants  \\\n",
       "0                               PySRFunction(X=>x69)                 0   \n",
       "1          PySRFunction(X=>x13 - 2.7246199129259274)                 1   \n",
       "2                     PySRFunction(X=>x69 - exp(x3))                 0   \n",
       "3    PySRFunction(X=>x13 + x16 - 3.1255318803272307)                 1   \n",
       "4  PySRFunction(X=>exp(exp(exp(x53))) + 4.3327990...                 1   \n",
       "5  PySRFunction(X=>x17 + x69 - exp(1.045152434643...                 1   \n",
       "6  PySRFunction(X=>0.78230302631069185*x16 + x5 +...                 2   \n",
       "7  PySRFunction(X=>0.78230302631069185*x16 + 0.80...                 3   \n",
       "8  PySRFunction(X=>x13 - log(exp(x5 + 6.715533487...                 2   \n",
       "\n",
       "   number_variables  unique_number_variables    log_like          aic  \n",
       "0                 1                        1 -528.493489  1056.986978  \n",
       "1                 1                        1  -31.215879    64.431757  \n",
       "2                 2                        2  -28.056389    56.112778  \n",
       "3                 2                        2  -18.930941    39.861882  \n",
       "4                 1                        1  -14.373573    30.747146  \n",
       "5                 3                        3  -14.254474    30.508948  \n",
       "6                 3                        3  -14.067884    32.135768  \n",
       "7                 3                        3  -12.900953    31.801906  \n",
       "8                 4                        4   -5.853746    15.707491  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equations = pd.read_csv('/data/zj448/SR/Ultimate_paper/pareto_archive/pareto_0_1.csv',index_col=0)\n",
    "equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
